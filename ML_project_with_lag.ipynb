{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "#url = 'https://raw.githubusercontent.com/TheLazyCactus/ML_Project/refs/heads/main/Extra_data.csv'\n",
    "#df = pd.read_csv(url, sep=\";\", low_memory =False)\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/TheLazyCactus/ML_Project/refs/heads/main/ML_Project_safety.csv'\n",
    "df = pd.read_csv(url, sep=\";\", low_memory =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to change the order to get the oldest value first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Company code</th>\n",
       "      <th>FAR total</th>\n",
       "      <th>TRIR total</th>\n",
       "      <th>TRIR company only</th>\n",
       "      <th>TRIR contractor only</th>\n",
       "      <th>LTIR total</th>\n",
       "      <th>LTIR company only</th>\n",
       "      <th>LTIR contractor only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2014</td>\n",
       "      <td>ZZ</td>\n",
       "      <td>0</td>\n",
       "      <td>3,61</td>\n",
       "      <td>0</td>\n",
       "      <td>5,43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2014</td>\n",
       "      <td>W</td>\n",
       "      <td>2,6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,37</td>\n",
       "      <td>0,37</td>\n",
       "      <td>0,37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2014</td>\n",
       "      <td>V</td>\n",
       "      <td>0</td>\n",
       "      <td>1,41</td>\n",
       "      <td>0,54</td>\n",
       "      <td>1,65</td>\n",
       "      <td>0,39</td>\n",
       "      <td>0,11</td>\n",
       "      <td>0,47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2014</td>\n",
       "      <td>U</td>\n",
       "      <td>7,03</td>\n",
       "      <td>1,97</td>\n",
       "      <td>1,21</td>\n",
       "      <td>2,2</td>\n",
       "      <td>0,49</td>\n",
       "      <td>0,61</td>\n",
       "      <td>0,46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2014</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>4,47</td>\n",
       "      <td>2,57</td>\n",
       "      <td>6,24</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,51</td>\n",
       "      <td>0,48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>GG</td>\n",
       "      <td>1,06</td>\n",
       "      <td>0,38</td>\n",
       "      <td>0,8</td>\n",
       "      <td>0,32</td>\n",
       "      <td>0,18</td>\n",
       "      <td>0,51</td>\n",
       "      <td>0,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>FF</td>\n",
       "      <td>1,34</td>\n",
       "      <td>0,98</td>\n",
       "      <td>0,75</td>\n",
       "      <td>1,07</td>\n",
       "      <td>0,18</td>\n",
       "      <td>0,15</td>\n",
       "      <td>0,19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023</td>\n",
       "      <td>EE</td>\n",
       "      <td>0</td>\n",
       "      <td>0,46</td>\n",
       "      <td>0,33</td>\n",
       "      <td>0,51</td>\n",
       "      <td>0,18</td>\n",
       "      <td>0,33</td>\n",
       "      <td>0,13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>CC</td>\n",
       "      <td>0</td>\n",
       "      <td>0,2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,24</td>\n",
       "      <td>0,2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>A</td>\n",
       "      <td>93,56</td>\n",
       "      <td>2,57</td>\n",
       "      <td>2,74</td>\n",
       "      <td>2,42</td>\n",
       "      <td>2,22</td>\n",
       "      <td>2,24</td>\n",
       "      <td>2,2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year Company code FAR total TRIR total TRIR company only  \\\n",
       "486  2014   ZZ                 0       3,61                 0   \n",
       "456  2014   W                2,6        NaN               NaN   \n",
       "455  2014   V                  0       1,41              0,54   \n",
       "454  2014   U               7,03       1,97              1,21   \n",
       "453  2014   T                  0       4,47              2,57   \n",
       "..    ...          ...       ...        ...               ...   \n",
       "31   2023   GG              1,06       0,38               0,8   \n",
       "30   2023   FF              1,34       0,98              0,75   \n",
       "29   2023   EE                 0       0,46              0,33   \n",
       "27   2023   CC                 0        0,2                 0   \n",
       "0    2023   A              93,56       2,57              2,74   \n",
       "\n",
       "    TRIR contractor only LTIR total LTIR company only LTIR contractor only  \n",
       "486                 5,43          0                 0                    0  \n",
       "456                  NaN       0,37              0,37                 0,37  \n",
       "455                 1,65       0,39              0,11                 0,47  \n",
       "454                  2,2       0,49              0,61                 0,46  \n",
       "453                 6,24        0,5              0,51                 0,48  \n",
       "..                   ...        ...               ...                  ...  \n",
       "31                  0,32       0,18              0,51                 0,13  \n",
       "30                  1,07       0,18              0,15                 0,19  \n",
       "29                  0,51       0,18              0,33                 0,13  \n",
       "27                  0,24        0,2                 0                 0,24  \n",
       "0                   2,42       2,22              2,24                  2,2  \n",
       "\n",
       "[487 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"Year\", ascending=True)\n",
    "#Drop FAR\n",
    "df.drop(\"FAR total\", axis = 1, inplace=True)\n",
    "\n",
    "cols = [\"TRIR total\", \"TRIR company only\", \"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\" ]  # List of columns to convert\n",
    "df[cols] = df[cols].replace(',', '.', regex=True).astype(float)\n",
    "\n",
    "df[cols] = df[cols].astype(float)\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "original_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487, 8)\n",
      "Index(['Year', 'Company code', 'TRIR total', 'TRIR company only',\n",
      "       'TRIR contractor only', 'LTIR total', 'LTIR company only',\n",
      "       'LTIR contractor only'],\n",
      "      dtype='object')\n",
      "Year                      int64\n",
      "Company code             object\n",
      "TRIR total              float64\n",
      "TRIR company only       float64\n",
      "TRIR contractor only    float64\n",
      "LTIR total              float64\n",
      "LTIR company only       float64\n",
      "LTIR contractor only    float64\n",
      "dtype: object\n",
      "Year                     10\n",
      "Company code             59\n",
      "TRIR total              247\n",
      "TRIR company only       188\n",
      "TRIR contractor only    279\n",
      "LTIR total              121\n",
      "LTIR company only       105\n",
      "LTIR contractor only    138\n",
      "dtype: int64\n",
      "Year                    0\n",
      "Company code            0\n",
      "TRIR total              0\n",
      "TRIR company only       0\n",
      "TRIR contractor only    0\n",
      "LTIR total              0\n",
      "LTIR company only       0\n",
      "LTIR contractor only    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "print(df.nunique())\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df[[\"Year\", \"Company code\", \"TRIR total\", \"LTIR total\"]]\n",
    "df_company = df[[\"Year\", \"Company code\", \"TRIR company only\", \"LTIR company only\"]]\n",
    "df_contractor = df[[\"Year\", \"Company code\", \"TRIR contractor only\", \"LTIR contractor only\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Serie for TRIR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ARIMA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts cygdb.exe, cython.exe and cythonize.exe are installed in 'd:\\Data_analyst\\Ironhack\\Anaconda\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pmdarima\n",
      "  Downloading pmdarima-2.0.4-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pmdarima) (1.4.2)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima)\n",
      "  Downloading Cython-3.0.12-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pmdarima) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.19 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pmdarima) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pmdarima) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pmdarima) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pmdarima) (0.14.2)\n",
      "Requirement already satisfied: urllib3 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pmdarima) (2.2.2)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pmdarima) (69.5.1)\n",
      "Requirement already satisfied: packaging>=17.1 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pmdarima) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pandas>=0.19->pmdarima) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from pandas>=0.19->pmdarima) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from scikit-learn>=0.22->pmdarima) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.6)\n",
      "Requirement already satisfied: six in d:\\data_analyst\\ironhack\\anaconda\\lib\\site-packages (from patsy>=0.5.6->statsmodels>=0.13.2->pmdarima) (1.16.0)\n",
      "Downloading pmdarima-2.0.4-cp312-cp312-win_amd64.whl (625 kB)\n",
      "   ---------------------------------------- 0.0/625.1 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/625.1 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 41.0/625.1 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------- -------------------------- 204.8/625.1 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 501.8/625.1 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 625.1/625.1 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading Cython-3.0.12-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.4/2.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.8/2.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.8/2.8 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.2/2.8 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.7/2.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: Cython, pmdarima\n",
      "Successfully installed Cython-3.0.12 pmdarima-2.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts cygdb.exe, cython.exe and cythonize.exe are installed in 'd:\\Data_analyst\\Ironhack\\Anaconda\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install pmdarima --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_counts = df_total.groupby(\"Company code\")[\"Year\"].count()\n",
    "# Get companies with 5 or more rows\n",
    "valid_companies = company_counts[company_counts >= 5].index\n",
    "\n",
    "# Filter the original DataFrame to keep only those companies\n",
    "df_total_filtered = df_total[df_total[\"Company code\"].isin(valid_companies)]\n",
    "df_total_filtered = df_total_filtered.set_index(\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Company code</th>\n",
       "      <th>TRIR total</th>\n",
       "      <th>LTIR total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2014</td>\n",
       "      <td>W</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2014</td>\n",
       "      <td>V</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2014</td>\n",
       "      <td>U</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2014</td>\n",
       "      <td>T</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2014</td>\n",
       "      <td>S</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>GG</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>FF</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023</td>\n",
       "      <td>EE</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>CC</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>A</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>473 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year Company code  TRIR total  LTIR total\n",
       "456  2014   W                 0.00        0.37\n",
       "455  2014   V                 1.41        0.39\n",
       "454  2014   U                 1.97        0.49\n",
       "453  2014   T                 4.47        0.50\n",
       "452  2014   S                 1.29        0.53\n",
       "..    ...          ...         ...         ...\n",
       "31   2023   GG                0.38        0.18\n",
       "30   2023   FF                0.98        0.18\n",
       "29   2023   EE                0.46        0.18\n",
       "27   2023   CC                0.20        0.20\n",
       "0    2023   A                 2.57        2.22\n",
       "\n",
       "[473 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year             10\n",
       "Company code     50\n",
       "TRIR total      243\n",
       "LTIR total      121\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_filtered.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year              int64\n",
       "Company code     object\n",
       "TRIR total      float64\n",
       "LTIR total      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_filtered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company: W         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: V         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: U         \n",
      "company_df.shape: (9, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: T         \n",
      "company_df.shape: (9, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: S         \n",
      "company_df.shape: (9, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: R         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: Q         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: P         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: O         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: N         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: M         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: L         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: K         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: J         \n",
      "company_df.shape: (10, 3), preds.shape: (9, 1), residuals.shape: (9, 1)\n",
      "Company: I         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: H         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: G         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: F         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: E         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: D         \n",
      "company_df.shape: (10, 3), preds.shape: (9, 1), residuals.shape: (9, 1)\n",
      "Company: C         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: B         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: A         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: Overall   \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: X         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: AA        \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: Y         \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: WW        \n",
      "company_df.shape: (5, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: VV        \n",
      "company_df.shape: (5, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: UU        \n",
      "company_df.shape: (7, 3), preds.shape: (9, 1), residuals.shape: (9, 1)\n",
      "Company: TT        \n",
      "company_df.shape: (7, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: SS        \n",
      "company_df.shape: (7, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: RR        \n",
      "company_df.shape: (9, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: QQ        \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: PP        \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: OO        \n",
      "company_df.shape: (9, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: NN        \n",
      "company_df.shape: (10, 3), preds.shape: (9, 1), residuals.shape: (9, 1)\n",
      "Company: MM        \n",
      "company_df.shape: (10, 3), preds.shape: (9, 1), residuals.shape: (9, 1)\n",
      "Company: KK        \n",
      "company_df.shape: (10, 3), preds.shape: (7, 1), residuals.shape: (7, 1)\n",
      "Company: LL        \n",
      "company_df.shape: (10, 3), preds.shape: (9, 1), residuals.shape: (9, 1)\n",
      "Company: Z         \n",
      "company_df.shape: (9, 3), preds.shape: (7, 1), residuals.shape: (7, 1)\n",
      "Company: CC        \n",
      "company_df.shape: (10, 3), preds.shape: (9, 1), residuals.shape: (9, 1)\n",
      "⚠️ Warning: No predictions for Company DD        . Skipping...\n",
      "Company: EE        \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "⚠️ Warning: No predictions for Company BB        . Skipping...\n",
      "Company: GG        \n",
      "company_df.shape: (9, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "⚠️ Warning: No predictions for Company HH        . Skipping...\n",
      "Company: II        \n",
      "company_df.shape: (10, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: JJ        \n",
      "company_df.shape: (9, 3), preds.shape: (10, 1), residuals.shape: (10, 1)\n",
      "Company: FF        \n",
      "company_df.shape: (10, 3), preds.shape: (9, 1), residuals.shape: (9, 1)\n",
      "     Company code  TRIR total  LTIR total  Predictions  Residuals\n",
      "Year                                                             \n",
      "2014   W                 0.00        0.37     0.000000   4.340000\n",
      "2015   W                 1.41        0.38     6.510021  -2.450021\n",
      "2016   W                 1.17        0.28     3.780000  -1.330000\n",
      "2017   W                 0.76        0.25     0.840000   4.820000\n",
      "2018   W                 3.05        0.28     8.870000  -6.220000\n",
      "...           ...         ...         ...          ...        ...\n",
      "2019   FF                0.84        0.18     1.017046  -0.117046\n",
      "2020   FF                0.76        0.12     1.384425   0.585575\n",
      "2021   FF                0.49        0.14     1.902792  -1.292792\n",
      "2022   FF                0.40        0.11     1.275340  -0.455340\n",
      "2023   FF                0.98        0.18     0.660041   1.139959\n",
      "\n",
      "[431 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pmdarima as pm\n",
    "import pandas as pd\n",
    "\n",
    "# Function to fit ARIMA and return model summary (for Company only)\n",
    "def fit_arima(group):\n",
    "    company = group[\"Company code\"].iloc[0]  # Extract the company name\n",
    "    ts = group[\"TRIR total\"]  # Convert to time series using the 'TRIR total' column\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Fit ARIMA model\n",
    "        model = pm.auto_arima(ts, start_p=1, start_q=1, max_p=3, max_q=3, d=None, \n",
    "                              test=\"adf\", seasonal=False, trace=False, error_action=\"ignore\", \n",
    "                              suppress_warnings=True, stepwise=True)\n",
    "        \n",
    "        print(f\"Successfully fitted ARIMA for {company}\")  # Add a print statement to verify success\n",
    "        # Generate predictions and residuals\n",
    "        preds = model.predict_in_sample()  # In-sample predictions\n",
    "        residuals = ts.values - preds  # Residuals (actual - predicted)\n",
    "        return company, model, preds, residuals\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting ARIMA for {company}: {str(e)}\")\n",
    "        return company, None, None, None  \n",
    "\n",
    "\n",
    "# Debugging the fitting process and checking the data\n",
    "#print(df_total_filtered.groupby(\"Company code\")[\"Year\"].count())  # Number of rows per company\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "models = Parallel(n_jobs=-1)(delayed(fit_arima)(group) for _, group in df_total_filtered.groupby(\"Company code\"))\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for i, company_code in enumerate(df_total_filtered[\"Company code\"].unique()):\n",
    "    company_df = df_total_filtered[df_total_filtered[\"Company code\"] == company_code]\n",
    "\n",
    "    # Check if the model produced predictions\n",
    "    if models[i][2] is None or models[i][3] is None:\n",
    "        print(f\"⚠️ Warning: No predictions for Company {company_code}. Skipping...\")\n",
    "        continue  # Skip this company\n",
    "\n",
    "    preds = models[i][2].to_frame(name=\"Predictions\")  \n",
    "    residuals = models[i][3].to_frame(name=\"Residuals\")  \n",
    "\n",
    "    # Ensure \"Year\" is the index\n",
    "    if \"Year\" in company_df.columns:\n",
    "        company_df = company_df.set_index(\"Year\")\n",
    "\n",
    "    # Debugging: Print shapes before fixing mismatch\n",
    "    print(f\"Company: {company_code}\")\n",
    "    print(f\"company_df.shape: {company_df.shape}, preds.shape: {preds.shape}, residuals.shape: {residuals.shape}\")\n",
    "\n",
    "    # Fix length mismatch\n",
    "    min_len = min(len(company_df), len(preds), len(residuals))\n",
    "    company_df = company_df.iloc[-min_len:]  \n",
    "    preds = preds.iloc[-min_len:]  \n",
    "    residuals = residuals.iloc[-min_len:]  \n",
    "\n",
    "    # Assign correct index\n",
    "    preds.index = company_df.index\n",
    "    residuals.index = company_df.index\n",
    "\n",
    "    # Concatenate and append\n",
    "    final_df_rows = pd.concat([company_df, preds, residuals], axis=1)\n",
    "    final_df = pd.concat([final_df, final_df_rows], axis=0)\n",
    "\n",
    "print(final_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Predictions'] = final_df['Predictions'].apply(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company code</th>\n",
       "      <th>TRIR total</th>\n",
       "      <th>LTIR total</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Residuals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>W</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>W</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>6.510021</td>\n",
       "      <td>-2.450021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>W</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.780000</td>\n",
       "      <td>-1.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>W</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>4.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>W</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.28</td>\n",
       "      <td>8.870000</td>\n",
       "      <td>-6.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>FF</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.017046</td>\n",
       "      <td>-0.117046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>FF</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.384425</td>\n",
       "      <td>0.585575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>FF</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.902792</td>\n",
       "      <td>-1.292792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>FF</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.275340</td>\n",
       "      <td>-0.455340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>FF</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.660041</td>\n",
       "      <td>1.139959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>431 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company code  TRIR total  LTIR total  Predictions  Residuals\n",
       "Year                                                             \n",
       "2014   W                 0.00        0.37     0.000000   4.340000\n",
       "2015   W                 1.41        0.38     6.510021  -2.450021\n",
       "2016   W                 1.17        0.28     3.780000  -1.330000\n",
       "2017   W                 0.76        0.25     0.840000   4.820000\n",
       "2018   W                 3.05        0.28     8.870000  -6.220000\n",
       "...           ...         ...         ...          ...        ...\n",
       "2019   FF                0.84        0.18     1.017046  -0.117046\n",
       "2020   FF                0.76        0.12     1.384425   0.585575\n",
       "2021   FF                0.49        0.14     1.902792  -1.292792\n",
       "2022   FF                0.40        0.11     1.275340  -0.455340\n",
       "2023   FF                0.98        0.18     0.660041   1.139959\n",
       "\n",
       "[431 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit ARIMA Models for each company group\n",
    "#models = Parallel(n_jobs=-1)(delayed(fit_arima)(group) for _, group in df_total_filtered.groupby(\"Company code\"))\n",
    "#\n",
    "#\n",
    "#final_df = pd.DataFrame()\n",
    "#\n",
    "#\n",
    "#for i, company_code in enumerate(df_total_filtered[\"Company code\"].unique()):\n",
    "#    company_df = df_total_filtered[df_total_filtered[\"Company code\"] == company_code]\n",
    "#    preds = models[i][2]\n",
    "#    residuals = models[i][3]\n",
    "#    final_df_rows = pd.concat([company_df, preds, residuals], axis=1, ignore_index=False)\n",
    "#    print(final_df_rows)\n",
    "#    preds = preds.to_frame(name=\"Predictions\")  # Assign a column name\n",
    "#    residuals = residuals.to_frame(name=\"Residuals\") \n",
    "#    company_df = company_df.set_index(\"Year\")\n",
    "#    preds = preds.set_index(\"Year\")\n",
    "#    residuals = residuals.set_index(\"Year\")\n",
    "#    final_df = pd.concat([final_df, final_df_rows], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create lag features for LTIR total\n",
    "#final_df[\"LTIR_Lag_1\"] = final_df.groupby(\"Company code\")[\"LTIR total\"].shift(1)\n",
    "#final_df[\"LTIR_Lag_2\"] = final_df.groupby(\"Company code\")[\"LTIR total\"].shift(2)\n",
    "#\n",
    "## Drop rows with NaN values due to lagging\n",
    "#final_df = final_df.dropna(subset=[\"LTIR_Lag_1\", \"LTIR_Lag_2\"])\n",
    "#\n",
    "## Optionally, you can fill NaN values instead of dropping them, for example:\n",
    "#final_df[\"LTIR_Lag_1\"].fillna(0, inplace=True)\n",
    "#final_df[\"LTIR_Lag_2\"].fillna(final_df[\"LTIR total\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LTIR Prediction***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train test split without lag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for model stacking: TRIR ARIMA predictions and residuals\n",
    "final_df_reset = final_df.reset_index()\n",
    "X = final_df_reset[[\"Year\", \"TRIR total\", \"Predictions\", \"Residuals\", \"Company code\"]] \n",
    "X = pd.get_dummies(X, columns=[\"Company code\"], drop_first=True)\n",
    "y = final_df_reset[\"LTIR total\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model selection and evaluation only Model stacking for LTIR total, company and global**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.20805955036586077\n",
      "RMSE 0.3260792068241495\n",
      "R2 score (Test) 0.23166593389328505\n",
      "R2 score (Train) 0.8931014652529361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Class model\n",
    "forest = RandomForestRegressor(n_estimators=200,\n",
    "                             max_depth=10, random_state=42)\n",
    "model_forest = forest.fit(X_train, y_train)\n",
    "pred = forest.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score (Test)\", forest.score(X_test, y_test))\n",
    "print(\"R2 score (Train)\", forest.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bagging and Pasting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.204528015838353\n",
      "RMSE 0.3155874066408907\n",
      "R2 score 0.28031374804877773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bagging_reg = BaggingRegressor(DecisionTreeRegressor(max_depth=10),\n",
    "                               n_estimators=100,\n",
    "                               max_samples=100,\n",
    "                                random_state=42)#take 80% of the total samples\n",
    "\n",
    "model_bag = bagging_reg.fit(X_train, y_train)\n",
    "pred = bagging_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", bagging_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gradient Boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)  # Should print (376,) not (376, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.2041383199648172\n",
      "RMSE 0.3620685158638784\n",
      "R2 score 0.0527046597867592\n",
      "R2 score 0.99915642083061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gb_reg = GradientBoostingRegressor(max_depth=10,\n",
    "                                   n_estimators=100,\n",
    "                                   random_state=42)\n",
    "model_gb = gb_reg.fit(X_train, y_train)\n",
    "pred = gb_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", gb_reg.score(X_test, y_test))\n",
    "print(\"R2 score\", gb_reg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adaptive Boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.21252478815983442\n",
      "RMSE 0.3263387544679752\n",
      "R2 score 0.23044231301991092\n",
      "R2 score 0.9785828010197963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=10),\n",
    "                            n_estimators=100,\n",
    "                            random_state=42)\n",
    "model_ada = ada_reg.fit(X_train, y_train)\n",
    "pred = ada_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", ada_reg.score(X_test, y_test))\n",
    "print(\"R2 score\", ada_reg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With lag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for model stacking: TRIR ARIMA predictions and residuals\n",
    "final_df_reset = final_df.reset_index()\n",
    "X = final_df_reset[[\"Year\", \"TRIR total\", \"Predictions\", \"Residuals\", \"Company code\", \"LTIR_Lag_1\", \"LTIR_Lag_2\"]] \n",
    "X = pd.get_dummies(X, columns=[\"Company code\"], drop_first=True)\n",
    "y = final_df_reset[\"LTIR total\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.062186721718179745\n",
      "RMSE 0.1130349630646833\n",
      "R2 score (Test) 0.8952912343428158\n",
      "R2 score (Train) 0.9428636926020838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.05734840298023972\n",
      "RMSE 0.09367253371031917\n",
      "R2 score 0.9280912099289509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.08895206808890506\n",
      "RMSE 0.17667366220266706\n",
      "R2 score 0.7441996882304353\n",
      "R2 score 0.9999999992935337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.06714285714285713\n",
      "RMSE 0.11749945722844674\n",
      "R2 score 0.8868566150745893\n",
      "R2 score 0.9981445344439233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestRegressor(n_estimators=200,\n",
    "                             max_depth=10, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "pred = forest.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score (Test)\", forest.score(X_test, y_test))\n",
    "print(\"R2 score (Train)\", forest.score(X_train, y_train))\n",
    "\n",
    "bagging_reg = BaggingRegressor(DecisionTreeRegressor(max_depth=10),\n",
    "                               n_estimators=100,\n",
    "                               max_samples=100,\n",
    "                                random_state=42)#take 80% of the total samples\n",
    "\n",
    "bagging_reg.fit(X_train, y_train)\n",
    "pred = bagging_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", bagging_reg.score(X_test, y_test))\n",
    "\n",
    "gb_reg = GradientBoostingRegressor(max_depth=10,\n",
    "                                   n_estimators=100,\n",
    "                                   random_state=42)\n",
    "gb_reg.fit(X_train, y_train)\n",
    "pred = gb_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", gb_reg.score(X_test, y_test))\n",
    "print(\"R2 score\", gb_reg.score(X_train, y_train))\n",
    "\n",
    "ada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=10),\n",
    "                            n_estimators=100,\n",
    "                            random_state=42)\n",
    "ada_reg.fit(X_train, y_train)\n",
    "pred = ada_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", ada_reg.score(X_test, y_test))\n",
    "print(\"R2 score\", ada_reg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for MAE: [0.2542018  0.30642994 0.62502668 0.25200593 0.14606892]\n",
      "Average MAE: 0.31674665415721176\n",
      "Standard Deviation of MAE: 0.16271270484330935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#Let's try without lag\n",
    "X = final_df.drop(columns=['LTIR total'])  # Drop target variable\n",
    "X = pd.get_dummies(X, columns=[\"Company code\"], drop_first=True)\n",
    "y = final_df['LTIR total']  # Target variable\n",
    "\n",
    "# Instantiate the Random Forest Regressor model\n",
    "#rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_val_score(model_forest, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# cv_results returns the negative of the score (since lower MAE is better)\n",
    "# Convert it back to positive values\n",
    "cv_results = -cv_results\n",
    "\n",
    "# Print the results\n",
    "print(f\"Cross-validation results for MAE: {cv_results}\")\n",
    "print(f\"Average MAE: {np.mean(cv_results)}\")\n",
    "print(f\"Standard Deviation of MAE: {np.std(cv_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for MAE: [0.0710537  0.13101948 0.4430938  0.04985023 0.05046016]\n",
      "Average MAE: 0.14909547258208491\n",
      "Standard Deviation of MAE: 0.14995387365117138\n"
     ]
    }
   ],
   "source": [
    "#With lag\n",
    "X = final_df.drop(columns=['LTIR total'])  # Drop target variable\n",
    "X = pd.get_dummies(X, columns=[\"Company code\"], drop_first=True)\n",
    "y = final_df['LTIR total']  # Target variable\n",
    "\n",
    "# Instantiate the Random Forest Regressor model\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42, max_depth= 10)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_val_score(rf, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# cv_results returns the negative of the score (since lower MAE is better)\n",
    "# Convert it back to positive values\n",
    "cv_results = -cv_results\n",
    "\n",
    "# Print the results\n",
    "print(f\"Cross-validation results for MAE: {cv_results}\")\n",
    "print(f\"Average MAE: {np.mean(cv_results)}\")\n",
    "print(f\"Standard Deviation of MAE: {np.std(cv_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare MAE cross validation to train MAE\n",
    "If cross validation MAE too high compare to train MAE, model good for training sata but not for new data -> Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper param tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"n_estimators\": [50, 100, 200,500],\n",
    "        \"estimator__max_leaf_nodes\": [250, 500, 1000, None],\n",
    "        \"estimator__max_depth\":[10,30,50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_reg = RandomForestRegressor(DecisionTreeRegressor())\n",
    "model = GridSearchCV(estimator = random_reg, param_grid = grid, cv=5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "pred = random_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", root_mean_squared_error(pred, y_test))\n",
    "print(\"R2 score\", random_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the model for prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Company code_A         \n- Company code_AAA       \n- Company code_BB        \n- Company code_BBB       \n- Company code_CCC       \n- ...\nFeature names seen at fit time, yet now missing:\n- Predictions\n- Residuals\n- TRIR total\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 31\u001b[0m\n\u001b[0;32m     25\u001b[0m future_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(future_df, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompany code\u001b[39m\u001b[38;5;124m\"\u001b[39m], drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# If there are additional features that your model used (e.g., lagged variables), you'll need to add those to the future_df\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# For example, if you used lagged values for 'LTIR', you'd need to generate those for the future years\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Predict for the next 5 years using the trained model (RandomForestRegressor or similar)\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model_forest\u001b[38;5;241m.\u001b[39mpredict(future_df)  \u001b[38;5;66;03m# Use your trained model here\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Add the predictions to the future dataframe\u001b[39;00m\n\u001b[0;32m     34\u001b[0m future_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_LTIR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1064\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1062\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m-> 1064\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    642\u001b[0m     X,\n\u001b[0;32m    643\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    644\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    646\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    647\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Company code_A         \n- Company code_AAA       \n- Company code_BB        \n- Company code_BBB       \n- Company code_CCC       \n- ...\nFeature names seen at fit time, yet now missing:\n- Predictions\n- Residuals\n- TRIR total\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example: Assuming your last year in the dataset is 2023\n",
    "last_year = 2023\n",
    "years_to_predict = 5  # Predict for the next 5 years\n",
    "\n",
    "# Generate the future years\n",
    "future_years = np.arange(last_year + 1, last_year + 1 + years_to_predict)\n",
    "future_companies = original_df['Company code'].unique()  # assuming 'Company code' is present\n",
    "\n",
    "# Create an empty dataframe for future predictions\n",
    "future_data = []\n",
    "\n",
    "# Generate the future dataset for each company and each future year\n",
    "for company in future_companies:\n",
    "    for year in future_years:\n",
    "        future_data.append([company, year])\n",
    "\n",
    "# Convert the list to a dataframe\n",
    "future_df = pd.DataFrame(future_data, columns=[\"Company code\", \"Year\"])\n",
    "\n",
    "\n",
    "\n",
    "future_df = pd.get_dummies(future_df, columns=[\"Company code\"], drop_first=True)\n",
    "\n",
    "# If there are additional features that your model used (e.g., lagged variables), you'll need to add those to the future_df\n",
    "# For example, if you used lagged values for 'LTIR', you'd need to generate those for the future years\n",
    "\n",
    "# Predict for the next 5 years using the trained model (RandomForestRegressor or similar)\n",
    "predictions = model_forest.predict(future_df)  # Use your trained model here\n",
    "\n",
    "# Add the predictions to the future dataframe\n",
    "future_df['Predicted_LTIR'] = predictions\n",
    "\n",
    "# Print the predictions for the next 5 years\n",
    "print(future_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
