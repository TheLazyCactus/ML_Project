{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/TheLazyCactus/ML_Project/refs/heads/main/ML_Project_safety.csv'\n",
    "df = pd.read_csv(url, sep=\";\", low_memory =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Company code</th>\n",
       "      <th>FAR total</th>\n",
       "      <th>TRIR total</th>\n",
       "      <th>TRIR company only</th>\n",
       "      <th>TRIR contractor only</th>\n",
       "      <th>LTIR total</th>\n",
       "      <th>LTIR company only</th>\n",
       "      <th>LTIR contractor only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>A</td>\n",
       "      <td>93,56</td>\n",
       "      <td>2,57</td>\n",
       "      <td>2,74</td>\n",
       "      <td>2,42</td>\n",
       "      <td>2,22</td>\n",
       "      <td>2,24</td>\n",
       "      <td>2,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>3,39</td>\n",
       "      <td>2,01</td>\n",
       "      <td>4,22</td>\n",
       "      <td>1,51</td>\n",
       "      <td>1,01</td>\n",
       "      <td>1,81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>1,22</td>\n",
       "      <td>0,71</td>\n",
       "      <td>2,58</td>\n",
       "      <td>1,22</td>\n",
       "      <td>0,71</td>\n",
       "      <td>2,58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>2,41</td>\n",
       "      <td>0,93</td>\n",
       "      <td>3,76</td>\n",
       "      <td>1,1</td>\n",
       "      <td>0,46</td>\n",
       "      <td>1,67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>2,12</td>\n",
       "      <td>0</td>\n",
       "      <td>4,08</td>\n",
       "      <td>1,06</td>\n",
       "      <td>0</td>\n",
       "      <td>2,04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Company code FAR total TRIR total TRIR company only  \\\n",
       "0  2023   A              93,56       2,57              2,74   \n",
       "1  2023   B                  0       3,39              2,01   \n",
       "2  2023   C                  0       1,22              0,71   \n",
       "3  2023   D                  0       2,41              0,93   \n",
       "4  2023   E                  0       2,12                 0   \n",
       "\n",
       "  TRIR contractor only LTIR total LTIR company only LTIR contractor only  \n",
       "0                 2,42       2,22              2,24                  2,2  \n",
       "1                 4,22       1,51              1,01                 1,81  \n",
       "2                 2,58       1,22              0,71                 2,58  \n",
       "3                 3,76        1,1              0,46                 1,67  \n",
       "4                 4,08       1,06                 0                 2,04  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 9)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"FAR total\", \"TRIR total\", \"TRIR company only\",\"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\" ]  # List of columns to convert\n",
    "df[cols] = df[cols].replace(',', '.', regex=True).astype(float)\n",
    "\n",
    "df[cols] = df[cols].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                      int64\n",
       "Company code             object\n",
       "FAR total               float64\n",
       "TRIR total              float64\n",
       "TRIR company only       float64\n",
       "TRIR contractor only    float64\n",
       "LTIR total              float64\n",
       "LTIR company only       float64\n",
       "LTIR contractor only    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                     10\n",
       "Company code             59\n",
       "FAR total               126\n",
       "TRIR total              247\n",
       "TRIR company only       188\n",
       "TRIR contractor only    279\n",
       "LTIR total              121\n",
       "LTIR company only       105\n",
       "LTIR contractor only    138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                    0\n",
       "Company code            0\n",
       "FAR total               0\n",
       "TRIR total              3\n",
       "TRIR company only       4\n",
       "TRIR contractor only    4\n",
       "LTIR total              0\n",
       "LTIR company only       0\n",
       "LTIR contractor only    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Company code', 'FAR total', 'TRIR total', 'TRIR company only',\n",
       "       'TRIR contractor only', 'LTIR total', 'LTIR company only',\n",
       "       'LTIR contractor only'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummmies time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Company code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time serie transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: Check how lag works and how to work with time serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"FAR total\", \"TRIR total\", \"TRIR company only\",\"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\" ] :\n",
    "    df[f\"{col}_lag1\"] = df[col].shift(1)  # Value from the previous year\n",
    "    df[f\"{col}_lag2\"] = df[col].shift(2)  # Value from two years ago\n",
    "\n",
    "\n",
    "for col in [\"FAR total\", \"TRIR total\", \"TRIR company only\",\"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\" ]:\n",
    "    df[f\"{col}_rolling_mean\"] = df[col].rolling(window=3).mean()\n",
    "df.dropna(inplace=True)  # Drop NaN values created by shifting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and targets (y)\n",
    "X = df.drop(columns=[\"LTIR total\", \"LTIR company only\", \"LTIR contractor only\"])  # Features\n",
    "y = df[[\"LTIR total\", \"LTIR company only\", \"LTIR contractor only\"]]  # Target variables\n",
    "\n",
    "# Split the dataset (train on past data, test on future data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try with LTIR global only ? As gb and ab only works for one column\n",
    "Create multiple model for each KPIs with streamlit selection of what you want to see ?\n",
    "Sarimax model for time serie, good for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model selection and evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.10721287031055741\n",
      "RMSE 0.20366342931524148\n",
      "R2 score (Test) 0.6110160765038436\n",
      "R2 score (Train) 0.9498467843280824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Class model\n",
    "forest = RandomForestRegressor(n_estimators=100,\n",
    "                             max_depth=10, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "pred = forest.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score (Test)\", forest.score(X_test, y_test))\n",
    "print(\"R2 score (Train)\", forest.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For target with LTIR*3 and features with the rest\n",
    "MAE 0.10721287031055741\n",
    "RMSE 0.20366342931524148\n",
    "R2 score (Test) 0.6110160765038436\n",
    "R2 score (Train) 0.9498467843280824\n",
    "Ok scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bagging and Pasting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.10437617101043273\n",
      "RMSE 0.19848549053799866\n",
      "R2 score 0.6348792593513751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bagging_reg = BaggingRegressor(DecisionTreeRegressor(max_depth=10),\n",
    "                               n_estimators=100,\n",
    "                               max_samples=376,\n",
    "                                random_state=42)#take 80% of the total samples\n",
    "\n",
    "bagging_reg.fit(X_train, y_train)\n",
    "pred = bagging_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", bagging_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For target with LTIR*3 and features with the rest\n",
    "max depth =10\n",
    "n=100\n",
    "max samples =376\n",
    "\n",
    "MAE 0.10437617101043273\n",
    "RMSE 0.19848549053799866\n",
    "R2 score 0.6348792593513751\n",
    "Good scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gradient Boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)  # Should print (376,) not (376, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.1117864129037802\n",
      "RMSE 0.39307952363149157\n",
      "R2 score -0.1412316209504969\n",
      "R2 score 0.999999999294211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_train_gb = y_train[\"LTIR total\"] \n",
    "y_test_gb = y_test[\"LTIR total\"]\n",
    "gb_reg = GradientBoostingRegressor(max_depth=10,\n",
    "                                   n_estimators=100,\n",
    "                                   random_state=42)\n",
    "gb_reg.fit(X_train, y_train_gb)\n",
    "pred = gb_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test_gb))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test_gb, squared=False))\n",
    "print(\"R2 score\", gb_reg.score(X_test, y_test_gb))\n",
    "print(\"R2 score\", gb_reg.score(X_train, y_train_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB results (10,100,42):\n",
    "MAE 0.1117864129037802\n",
    "RMSE 0.39307952363149157\n",
    "R2 score -0.1412316209504969\n",
    "R2 score 0.999999999294211\n",
    "Small R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adaptive Boosting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.04495567375886524\n",
      "RMSE 0.18898996261512713\n",
      "R2 score 0.7361904989257821\n",
      "R2 score 0.9989796794681831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_train_ab = y_train[\"LTIR total\"] \n",
    "y_test_ab = y_test[\"LTIR total\"]\n",
    "ada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=10),\n",
    "                            n_estimators=100,\n",
    "                            random_state=42)\n",
    "ada_reg.fit(X_train, y_train_ab)\n",
    "pred = ada_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test_ab))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test_ab, squared=False))\n",
    "print(\"R2 score\", ada_reg.score(X_test, y_test_ab))\n",
    "print(\"R2 score\", ada_reg.score(X_train, y_train_ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ab results (10,100,42):\n",
    "MAE 0.04495567375886524\n",
    "RMSE 0.18898996261512713\n",
    "R2 score 0.7361904989257821\n",
    "R2 score 0.9989796794681831\n",
    "Best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression ?\n",
    "Sarimax = exogenous feature ? (Used for air pollution prediction) without it's Sarima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the model for prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_years = np.array(range(2025, 2031)).reshape(-1, 1)\n",
    "future_df = pd.DataFrame({\"Year\": future_years.flatten()})\n",
    "\n",
    "# Step 1: Create lag and rolling mean features for future data\n",
    "for col in [\"FAR total\", \"TRIR total\", \"TRIR company only\", \"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\"]:\n",
    "    future_df[f\"{col}_lag1\"] = np.nan  # Placeholder for lag1\n",
    "    future_df[f\"{col}_lag2\"] = np.nan  # Placeholder for lag2\n",
    "    future_df[f\"{col}_rolling_mean\"] = np.nan  # Placeholder for rolling mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Company_E         ',\n",
       " 'Company_F         ',\n",
       " 'Company_G         ',\n",
       " 'Company_H         ',\n",
       " 'Company_I         ',\n",
       " 'Company_J         ',\n",
       " 'Company_K         ',\n",
       " 'Company_L         ',\n",
       " 'Company_M         ',\n",
       " 'Company_N         ',\n",
       " 'Company_O         ',\n",
       " 'Company_P         ',\n",
       " 'Company_Q         ',\n",
       " 'Company_R         ',\n",
       " 'Company_S         ',\n",
       " 'Company_T         ',\n",
       " 'Company_V         ',\n",
       " 'Company_W         ',\n",
       " 'Company_X         ',\n",
       " 'Company_Y         ',\n",
       " 'Company_Overall   ',\n",
       " 'Company_AA        ',\n",
       " 'Company_BB        ',\n",
       " 'Company_CC        ',\n",
       " 'Company_DD        ',\n",
       " 'Company_EE        ',\n",
       " 'Company_FF        ',\n",
       " 'Company_GG        ',\n",
       " 'Company_HH        ',\n",
       " 'Company_II        ',\n",
       " 'Company_KK        ',\n",
       " 'Company_LL        ',\n",
       " 'Company_MM        ',\n",
       " 'Company_NN        ',\n",
       " 'Company_OO        ',\n",
       " 'Company_PP        ',\n",
       " 'Company_QQ        ',\n",
       " 'Company_RR        ',\n",
       " 'Company_SS        ',\n",
       " 'Company_TT        ',\n",
       " 'Company_UU        ',\n",
       " 'Company_VV        ',\n",
       " 'Company_WW        ',\n",
       " 'Company_AAA       ',\n",
       " 'Company_BBB       ',\n",
       " 'Company_CCC       ',\n",
       " 'Company_DDD       ',\n",
       " 'Company_EEE       ',\n",
       " 'Company_XX        ',\n",
       " 'Company_YY        ',\n",
       " 'Company_ZZ        ',\n",
       " 'Company_A         ',\n",
       " 'Company_B         ',\n",
       " 'Company_C         ',\n",
       " 'Company_D         ',\n",
       " 'Company_U         ',\n",
       " 'Company_Z         ',\n",
       " 'Company_JJ        ',\n",
       " 'Company_00        ']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: One-hot encode the 'Company code' for future data\n",
    "companies = df['Company code'].unique()  # Get unique company codes used in training\n",
    "company_cols = [f'Company_{company}' for company in companies]  # List of one-hot encoded company columns\n",
    "\n",
    "company_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with zeros for future_df (since future_df doesn't have companies yet, assume 0s)\n",
    "for col in company_cols:\n",
    "    future_df[col] = 0\n",
    "\n",
    "# Step 3: Add lag and rolling mean data from the most recent year in the historical data\n",
    "# We'll take the last row of your historical data (i.e., the latest year) and use it for future data as placeholders.\n",
    "latest_data = model_df.iloc[-1]\n",
    "\n",
    "# Loop through each feature to assign the latest available data for the future years\n",
    "for col in [\"FAR total\", \"TRIR total\", \"TRIR company only\", \"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\"]:\n",
    "    future_df[f\"{col}_lag1\"] = latest_data[col]  # Assign latest value as lag1 for future\n",
    "    future_df[f\"{col}_lag2\"] = latest_data[col]  # Assign latest value as lag2 for future\n",
    "    future_df[f\"{col}_rolling_mean\"] = latest_data[col]  # Use latest value as rolling mean placeholder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Align features for future data (same as used in training)\n",
    "# Assuming the model was trained with the same set of features, align these columns for prediction.\n",
    "future_df_with_features = future_df[[\"Year\"] + company_cols + \n",
    "                                     [\"FAR total_lag1\", \"FAR total_lag2\", \"FAR total_rolling_mean\", \n",
    "                                      \"TRIR total_lag1\", \"TRIR total_lag2\", \"TRIR total_rolling_mean\", \n",
    "                                      \"LTIR total_lag1\", \"LTIR total_lag2\", \"LTIR total_rolling_mean\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Company_00        \n- Company_A         \n- Company_AA        \n- Company_AAA       \n- Company_B         \n- ...\nFeature names seen at fit time, yet now missing:\n- Company code_A         \n- Company code_AA        \n- Company code_AAA       \n- Company code_B         \n- Company code_BB        \n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 5: Use the trained model to predict future values\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming that your model has already been trained, use it to predict.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m future_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(future_df_with_features)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Step 6: Store predictions in the dataframe\u001b[39;00m\n\u001b[0;32m      6\u001b[0m future_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRIR total\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRIR company only\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRIR contractor only\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLTIR total\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLTIR company only\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLTIR contractor only\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m future_predictions\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1064\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1062\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m-> 1064\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    642\u001b[0m     X,\n\u001b[0;32m    643\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    644\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    646\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    647\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Company_00        \n- Company_A         \n- Company_AA        \n- Company_AAA       \n- Company_B         \n- ...\nFeature names seen at fit time, yet now missing:\n- Company code_A         \n- Company code_AA        \n- Company code_AAA       \n- Company code_B         \n- Company code_BB        \n- ...\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Use the trained model to predict future values\n",
    "# Assuming that your model has already been trained, use it to predict.\n",
    "future_predictions = model.predict(future_df_with_features)\n",
    "\n",
    "# Step 6: Store predictions in the dataframe\n",
    "future_df[[\"TRIR total\", \"TRIR company only\", \"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\"]] = future_predictions\n",
    "\n",
    "# Step 7: Print out the future predictions dataframe\n",
    "print(future_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"FAR total\", \"TRIR total\", \"TRIR company only\",\"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\" ]:\n",
    "    df[f\"{col}_rolling_mean\"] = df[col].rolling(window=3).mean()\n",
    "df.dropna(inplace=True)  # Drop NaN values created by shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Company code\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and targets (y)\n",
    "X = df.drop(columns=[\"FAR total\", \"TRIR total\", \"TRIR company only\",\"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\"])  # Features\n",
    "y = df[[ \"TRIR total\", \"TRIR company only\",\"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\"]]  # Target variables\n",
    "\n",
    "# Split the dataset (train on past data, test on future data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.3491333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Initialize model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Company code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Company code'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m future_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m: future_years\u001b[38;5;241m.\u001b[39mflatten()})\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Step 2: One-hot encode the company column for the future data (like you did during training)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Assuming df has the 'Company code' column from the original dataset\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m companies \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()  \u001b[38;5;66;03m# Get unique company codes used in training\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Make sure that 'Company code' column exists in the future_df (otherwise, add it)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Add a placeholder company data for future predictions (you can modify this as needed)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m future_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m companies[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# This is just an example, adjust as needed\u001b[39;00m\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Data_analyst\\Ironhack\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Company code'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Prepare the future years (2025-2030)\n",
    "future_years = np.array(range(2025, 2031)).reshape(-1, 1)  # Example: Predict for 2025-2030\n",
    "\n",
    "# Create a DataFrame for future years\n",
    "future_df = pd.DataFrame({\"Year\": future_years.flatten()})\n",
    "\n",
    "# Step 2: One-hot encode the company column for the future data (like you did during training)\n",
    "# Assuming df has the 'Company code' column from the original dataset\n",
    "companies = df['Company code'].unique()  # Get unique company codes used in training\n",
    "\n",
    "# Make sure that 'Company code' column exists in the future_df (otherwise, add it)\n",
    "# Add a placeholder company data for future predictions (you can modify this as needed)\n",
    "future_df['Company code'] = companies[0]  # This is just an example, adjust as needed\n",
    "\n",
    "# One-hot encode the 'Company code' column (future_df should have the same structure as training data)\n",
    "future_companies_df = pd.get_dummies(future_df['Company code'], prefix='Company', columns=companies)\n",
    "\n",
    "# Add missing columns for companies not in future data\n",
    "for company in companies:\n",
    "    if f'Company_{company}' not in future_companies_df.columns:\n",
    "        future_companies_df[f'Company_{company}'] = 0\n",
    "\n",
    "# Concatenate one-hot encoded columns to future_df\n",
    "future_df = pd.concat([future_df, future_companies_df], axis=1)\n",
    "\n",
    "# Step 3: Use the trained model to predict future values\n",
    "# Assuming the model is already trained, you can now make predictions on future_df\n",
    "future_predictions = model.predict(future_df)\n",
    "\n",
    "# Step 4: Store predictions in the dataframe\n",
    "future_df[[ \"TRIR total\", \"TRIR company only\", \"TRIR contractor only\", \"LTIR total\", \"LTIR company only\", \"LTIR contractor only\"]] = future_predictions\n",
    "\n",
    "# Step 5: Print out the future predictions dataframe\n",
    "print(future_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
